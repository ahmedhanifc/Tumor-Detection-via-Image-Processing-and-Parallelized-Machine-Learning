{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3723f6d2-977d-40f1-9667-5ea32cffc151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import read_images\n",
    "from src.functions import *\n",
    "from src.sequential import *\n",
    "from src.parallel import apply_filters_parallel, process_images_threading, model_training_thread\n",
    "from src.performanceMetrics import *\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec971e3b-c979-4b5d-a791-11cf22899059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'yes' images: 86\n",
      "Number of 'no' images: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 86/86 [1:03:49<00:00, 44.53s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 85/85 [29:13<00:00, 20.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequential Execution Time is:  5583.869168519974\n"
     ]
    }
   ],
   "source": [
    "save_count = 1\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = './data/brain_tumor_dataset/'\n",
    "\n",
    "# List all image files in the 'yes' and 'no' directories\n",
    "yes_images = glob.glob(dataset_path + 'yes/*.jpg')\n",
    "no_images = glob.glob(dataset_path + 'no/*.jpg')\n",
    "\n",
    "yes_images = read_images(yes_images)\n",
    "no_images = read_images(no_images)\n",
    "\n",
    "print(f\"Number of 'yes' images: {len(yes_images)}\")\n",
    "print(f\"Number of 'no' images: {len(no_images)}\")\n",
    "\n",
    "#image = yes_images[0]\n",
    "#filtered_images = apply_filter(image)\n",
    "#display_image(filtered_images,\"./plots/test_one\")\n",
    "# Testing on Three Images\n",
    "yes_test =yes_images\n",
    "no_test = no_images\n",
    "\n",
    "\n",
    "sequential_time_yes = process_images_sequentially(yes_test)\n",
    "sequential_time_no = process_images_sequentially(no_test)\n",
    "total_sequential_time = sequential_time_yes + sequential_time_no\n",
    "print(\"Total Sequential Execution Time is: \", total_sequential_time)    \n",
    "\n",
    "results1, time_yes_test = apply_filters_parallel(yes_test)\n",
    "\n",
    "results2, time_no_test = apply_filters_parallel(no_test)\n",
    "\n",
    "\n",
    "total_threading_time = []\n",
    "non_parallel_time = []\n",
    "f = []\n",
    "P = []\n",
    "speedup = []\n",
    "efficiency = []\n",
    "amdahl_upper_limit = []\n",
    "amdahl = []\n",
    "gustafson = []\n",
    "\n",
    "def printMetrics(key, NUM_PROCESSES):\n",
    "    f.append(non_parallel_time[key] / total_sequential_time)\n",
    "    P.append(1 - f[key])\n",
    "    print(\"Total Threading Execution Time is: \", total_threading_time[key])\n",
    "    \n",
    "    speedup.append(calculateSpeedup(total_sequential_time, total_threading_time[key]))\n",
    "    efficiency.append(calculateEfficiency(speedup[key], NUM_PROCESSES))\n",
    "    amdahl_upper_limit.append(calculateAmdhalUpperLimit(P[key]))\n",
    "    amdahl.append(calculateAmdhal(P[key],NUM_PROCESSES))\n",
    "    gustafson.append(calculateGustafson(P[key],NUM_PROCESSES))\n",
    "    interpretMetrics(NUM_PROCESSES, speedup[key], efficiency[key], P[key], amdahl_upper_limit[key], amdahl[key], gustafson[key])\n",
    "\n",
    "total_threading_time.append(time_yes_test[\"total_time\"] + time_no_test[\"total_time\"])\n",
    "non_parallel_time.append(time_yes_test[\"non_parallel_time\"] + time_no_test[\"non_parallel_time\"])\n",
    "print(\"-\"*40)\n",
    "print(\"Metrics for Applying Filters\")\n",
    "key = 0\n",
    "NUM_PROCESSES = 6\n",
    "printMetrics(key, NUM_PROCESSES)\n",
    "\n",
    "\n",
    "write_dict_to_pickle(f\"./data/filtered_images/filtered_yes_images_{save_count}\", results1)\n",
    "write_dict_to_pickle(f\"./data/filtered_images/filtered_no_images_{save_count}\", results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e44775-824c-4e14-9ab3-dbc34d72ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part Two\n",
    "\n",
    "glcm_results_1, time_glcm_results_1 = process_images_threading(results1,1)\n",
    "glcm_results_2, time_glcm_results_2 = process_images_threading(results2,0)\n",
    "\n",
    "total_threading_time.append(time_glcm_results_1[\"total_time\"] + time_glcm_results_2[\"total_time\"])\n",
    "non_parallel_time.append(time_glcm_results_1[\"non_parallel_time\"] + time_glcm_results_2[\"non_parallel_time\"])\n",
    "\n",
    "aggregated_dicts_result = aggregate_dicts(glcm_results_1,glcm_results_2)\n",
    "df = create_and_shuffle_df(aggregated_dicts_result)\n",
    "\n",
    "key +=1\n",
    "NUM_PROCESSES = 5\n",
    "print(\"-\"*40)\n",
    "print(\"Metrics for Calculating GLCM\")\n",
    "\n",
    "printMetrics(key, NUM_PROCESSES)\n",
    "\n",
    "key +=1\n",
    "\n",
    "\n",
    "write_dict_to_pickle(f\"./data/glcm_results/yes_images_glcm_result_{save_count}\",glcm_results_1)\n",
    "write_dict_to_pickle(f\"./data/glcm_results/no_images_glcm_result_{save_count}\",glcm_results_2)\n",
    "df.to_excel(f\"./data/glcm_results/glcm_dataset_{save_count}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2893befe-d829-4856-884c-b193ffe52086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(key, NUM_PROCESSES):\n",
    "    f.append(non_parallel_time[key] / total_sequential_time)\n",
    "    P.append(1 - f[key])\n",
    "    print(\"Total Threading Execution Time is: \", total_threading_time[key])\n",
    "    \n",
    "    speedup.append(calculateSpeedup(total_sequential_time, total_threading_time[key]))\n",
    "    efficiency.append(calculateEfficiency(speedup[key], NUM_PROCESSES))\n",
    "    amdahl_upper_limit.append(calculateAmdhalUpperLimit(P[key]))\n",
    "    amdahl.append(calculateAmdhal(P[key],NUM_PROCESSES))\n",
    "    gustafson.append(calculateGustafson(P[key],NUM_PROCESSES))\n",
    "    interpretMetrics(NUM_PROCESSES, speedup[key], efficiency[key], P[key], amdahl_upper_limit[key], amdahl[key], gustafson[key])\n",
    "\n",
    "df = pd.read_excel(\"./data/glcm_results/dataset.xlsx\")\n",
    "non_parallel_time = []\n",
    "total_threading_time = []\n",
    "f = []\n",
    "P = []\n",
    "speedup = []\n",
    "efficiency = []\n",
    "amdahl_upper_limit = []\n",
    "amdahl = []\n",
    "gustafson = []\n",
    "\n",
    "key = 0\n",
    "total_sequential_time = 5204.6512\n",
    "NUM_PROCESSES= 5\n",
    "save_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa37970-6a27-4c3c-80f2-90023fe69c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model training complete!\n",
      "----------------------------------------\n",
      "Metrics for Calculating Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Part Three -- ML\n",
    "X = df.drop(\"Tumor\", axis = 1)\n",
    "y = df[\"Tumor\"]\n",
    "results, model_train_time = model_training_thread(X,y)\n",
    "\n",
    "total_threading_time.append(model_train_time[\"total_time\"])\n",
    "non_parallel_time.append(model_train_time[\"non_parallel_time\"])\n",
    "\n",
    "model_performance = convert_model_performance_to_dataframe(results)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Metrics for Calculating Model\")\n",
    "key+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd68075-4648-4923-b086-74197000dd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Performance\n",
      "Total Threading Execution Time is:  446.41511821746826\n",
      "Speedup: 11.658770 : NP: 5 : Superlinear Speedup.\n",
      "2.3317540054566823\n",
      "Efficiency: 2.331754 : NP: 5\n",
      "With Parallelizable Portion of 0.999999, the presence of a serial component 0.000001 sets a definitive upper bound on achievable speedup to 944771.459702, even when increasing processor count\n",
      "The current speedup is 4.999979.\n",
      "\n",
      "The achievable speedup is 5.000000. By scaling the problem size with number of processors, the system behaves as if it is 5.000000 times faster than the sequential version, despite the presence of sequential portion of 0.000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ML Performance\")\n",
    "printMetrics(0, NUM_PROCESSES)\n",
    "\n",
    "model_performance.to_excel(f\"./data/model_performance_{save_count}.xlsx\", index=False)\n",
    "\n",
    "models_from_df = model_performance[\"model\"]\n",
    "saveModels(models_from_df,f\"./data/models_{save_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efecbd8-8bdc-4d4d-8bc7-5069af8499c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dfeeae-70bc-46a6-a81d-9a9f6b33c79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
